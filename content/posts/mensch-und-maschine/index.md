+++
title = "Mensch und Maschine"
date = "2024-05-06"
draft = false
pinned = false
tags = ["Deutsch", "Reportage"]
image = "bild1-transformed.jpeg"
description = "Eine Reportage über das Thema Algorithmen von Alec und Aaron"
footnotes = ""
+++
# Mensch und Maschine: Wie viel Macht haben wir noch?

{{<lead>}}
Algorithmen und künstliche Intelligenz werden immer prominenter, doch wie abhängig sind wir wirklich?
{{</lead>}} 

![Der Kontakt zwischen Mensch und Maschine wird immer häufiger und direkter.](bild1-transformed.jpeg)

In einer Pause zwischen zwei Lektionen Einführung Wirtschaft und Recht (EWR) sieht Nicolas Kiechler, Fachlehrperson für Wirtschaft und Recht am Gymnasium Kirchenfeld, wie ein Schüler mithilfe von Copilot, der künstlichen Intelligenz von Microsoft, eine ganze HTML-Datei in eine einzige Zeile umschreibt. Obwohl er einer der jüngsten Lehrkräfte an dem gesamten Gymnasium ist, kam er in seinem Studium nicht in Kontakt mit ähnlichen Technologien: «Es war nicht so verbreitet, wie es heute der Fall ist.» Schüler heutzutage haben mehr Freiheit: «Verschiedenste Male wird das benutzt», sagt Kiechler über ChatGPT. Neugierde ist doch normal, oder? Aus diesem Grund treffen wir uns einige Wochen später online zum Interview: ChatGPT in der Schule, sollte das erlaubt sein? Der Gymnasiallehrer ist der Meinung, die Benutzung dieser Technologie sollte in Bildungsinstitutionen sogar gefördert werden: «Es ist ein Hilfsmittel, das den Schülerinnen und Schülern zur Verfügung steht», so Kiechler.

![Nicolas Kiechler, Fachlehrperson am Gymnasium Kirchenfeld](portrait.jpg)

Auf die Frage, ob diese Werkzeuge ohne Einschränkungen zur Verfügung gestellt werden sollten, weiss er keine klare Antwort: «Wenn ich bei ChatGPT zum Beispiel mir irgendetwas generieren lasse, muss ich einfach in der Lage sein zu urteilen: Ist das jetzt etwas Gutes oder nicht?» Dafür müsse man die Materie auch zu einem gewissen Grad verstehen.

{{<box>}}

ChatGPT ist eine sprachbasierte künstliche Intelligenz, die seit Ende 2019 der Öffentlichkeit zur Verfügung steht. Die KI kann sich auf natürliche Weise mit Benutzern unterhalten und auf Fragen antworten. Die neuste Version (stand April 2024) kann sogar das Internet für den Benutzer durchsuchen – etwas, was der Vorgänger aus Sicherheitsgründen nicht konnte. Dies führte zu verbesserten, aber immer noch fehlerhaften, Antworten.

{{</box>}}

Das dazugehörige Urteilsvermögen könne den Schülern jedoch fehlen. Der Umgang mit diesen generativen KIs müsste also bewusst gesteuert und kontrolliert werden. Eine mögliche Gefährdung sieht er bereits darin, dass eine Faulheit entstehen würde. Wenn man alles manuell machen würde, müsse man für Microsoft Excel mehr wissen, als wenn man alles von einer KI generieren lassen würde. Die «Bequemlichkeit», die durch diese einfachere Lösung – Künstlicher Intelligenz – entstehe, sieht Nicolas Kiechler auch an der Berufsschule, an der er ebenfalls unterrichtet: «Dort werden Mails teilweise ausschliesslich mit ChatGPT geschrieben», schriftliche Texte zu verlangen, wäre «Voll der Fehler».

## Ungleichheiten bleiben

Weder Menschen noch Algorithmen sind gänzlich neutral und nicht immer geeignet. In einem Bericht von algorithmwatch.ch wird beschrieben, wie sogenannte «Applicant Tracking Systems», auch ATS genannt, benutzt werden. «Durch den Einsatz solcher Systeme können diskriminierende Muster verschärft werden oder gar neue entstehen», behauptet algorithmwatch.ch. Diese «Applicant Tracking Systems» sind in der Regel immer noch herkömmliche Abläufe, die vom Menschen programmiert werden. KI-basierte Systeme werden allerdings bereits in allen möglichen Anwendungen getestet und dürften in Zukunft auch von verschiedenen Unternehmen eingesetzt werden, um Kosten einzusparen. In einer Untersuchung von Findhr.eu wurden ATS mit ausgebildeten Experten in diesem Gebiet verglichen. Sie kam zum Schluss, dass viele der Bewerbenden, die von den Fachpersonen als Top-Kandidaten ausgewählt wurden, von den ATS viel tiefer eingestuft wurden. Der Grund? Findhr.eu vermutet, dass «Applicant Tracking Systems» nicht alle Lebensläufe und Bewerbungen gleich gut lesen könnten und diese in einer bestimmten Struktur bevorzugen würden. Sogar Rassismus sei ein Problem, zeigt ein britischer Bericht von Findhr.eu. Die KI-basierten Systeme zeigten eine Tendenz, Migranten auszuschliessen, obwohl sie besser für den Job geeignet gewesen wären. Selbst mit einem Abschluss an einer Hochschule im Ausland, würde man mit einer Wahrscheinlichkeit von ungefähr 80% eine tiefere Bewertung erhalten. Diese Ergebnisse seien nicht absolut und bräuchten weitere internationale Überprüfung und Bestätigung, jedoch ist ein beängstigender Trend sichtbar. Künstliche Intelligenzen nehmen rassistische und sexistische Angewohnheiten an, da sie von älteren Datensets lernen, in denen diese – heute inkorrekten – Haltungen präsent waren. Diese Algorithmen geben also nur die menschlichen rassistischen Muster wieder. Gesellschaftliche Kritiken gegenüber diesen Verhaltensmustern können sich aber auch negativ auswirken: Die generative Bilderstellungs-KI von OpenAI, DALL-E, wurde dafür kritisiert, zu viele «weisse» Bilder zu erstellen, was in der «Imagen» KI von Google überkompensiert wurde: Historische Figuren werden teilweise mit falscher Hautfarbe generiert.

{{<box>}}

ATS oder Applicant Tracking Systems, auf Deutsch Bewerbermanagementsystem, sind Algorithmen, die Job-Kandidaten automatisch nach Qualifikation filtern und auswählen sollen. Dafür analysiert es Bewerbungen und vergleicht diese mit einer Datenbank, um die besten herauszufiltern.

{{</box>}}

## Sind wir KI-abhängig?

Als komfortables und unkompliziertes Hilfsmittel ist KI gerne die erste Anlaufstelle bei Problemen.  Entwickeln wir so eine Abhängigkeit? Eindeutig, findet Jean-Marc	 Leutenegger, Informatikleiter der BLS: «Es wird so sein, wie es ist, und die Abhängigkeit ist da». Bereits heutzutage finde man diese: Die Bern-Lötschberg-Simplon-Bahn (BLS), könne ohne ihr Ressourcenplanungssystem langfristig nicht funktionieren. Im Gegensatz zu Kiechler  empfindet er diese Situation jedoch als weitaus weniger schlimm: «Ich finde, Technologie und die Möglichkeiten, die Technologie bieten, die sind brillant, das ist genial.» Massnahmen werden bei solch wichtigen Systemen aber immer ergriffen: «Wenn wir wissen, dass ein System für den operativen Betrieb des Unternehmens, also bei uns jetzt Zugfahren zum Beispiel, kritisch ist und dass man ohne dieses System nicht fahren kann, dann muss man einfach schauen, dass das System stabil ist und entsprechend dann, wenn es eine Panne gibt, dass man dann sofort reagieren kann.» Eine Voreingenommenheit sieht er bei sich selbst natürlich auch. Angst haben muss man also nach ihm nicht, es sei keine andere Entwicklung, als es sie auch schon in der Vergangenheit gegeben habe. Als Beispiel gab er uns das Smartphone: Er sei ohne ein solches aufgewachsen, aber er würde es selbst nicht mehr freiwillig weglegen. Solche Veränderungen und Entwicklungen seien also nichts Neues in dem Sinn, Zweifel seien normal, doch Versuche, diese technische Entwicklung aufzuhalten, wären nutzlos: «Was technologisch möglich ist, wird gemacht. Immer. Irgendwo. Das ist so. Man kann die Innovation und die technologischen Möglichkeiten nicht einschränken, dass es nicht gemacht wird. Klappt nicht.»

![Jean-Marc Leutenegger Leiter der Informatik BLS ](leutenegger.jpeg)

 Sicherheit ist jedoch nicht das einzige Problem: Privatsphäre wird gerade intensiv in verschiedenen Staaten diskutiert. Gerade weil die Benutzung künstlicher Intelligenzen zunimmt und zunehmen wird, entstehen immer mehr Konflikte, zum Beispiel Urheberrechtsverletzungen bei Bildern, die verwendet wurden, um generative KIs zu trainieren. Diese urheberrechtlich geschützten Bilder können dann von der KI als «Inspiration» für «neue» Bilder benutzt werden. Laut Leutenegger ist das aber kein Grund zur Sorge, es würden sich in der Zukunft Regeln und Gesetzte einpendeln, mit denen schliesslich eine korrekte und faire Benutzung gewährleistet werden kann.

{{<box>}}

Das Ressourcenplanungssystem der BLS plant den Verkehr der Züge. Dieses System der BLS ist im Grunde genommen ein Kompatibilitäts-Prüfer. Es teilt Lokführer auf gewisse Strecken, auf denen sie zertifiziert sind, zu. Den Lokführern wird ein Zug zugewiesen, der speziell für die zu befahrende Strecke geeignet ist.

{{</box>}}

## Entwicklung – Eine Gefahr für die Gesellschaft?

Algorithmen sind also grundsätzlich nicht gefährlich für den Menschen – oder etwa doch? Eines der Hauptthemen der aktuellen technologischen Entwicklung ist die Automatisierung von Arbeitsplätzen. Im vergangenen Jahrzehnt sind in Europa bereits über eineinhalb Millionen Jobs durch die Automatisierung weggefallen. Werden in Zukunft also Jobs eine wertvolle Seltenheit sein? Ganz klar nicht, meint Leutenegger: «Jede Technologie schafft mehr Arbeitsplätze, als sie zerstört.» Das heisst allerdings nicht, dass es gar keine Probleme gibt. «Man muss Leute ausbilden, die die neu geschaffenen Arbeitsplätze belegen, also ausüben. Das Problem daran ist, dass es dann immer wieder Verlierer gibt. Nämlich diejenigen, die ihre Arbeitsplätze verlieren, wegen der Technologie.» Man könnte allerdings Leutenegger entgegenhalten, dass – sollten in Zukunft eine beträchtliche Anzahl Stellen ersetzt werden – viele Jobs für weniger qualifizierte Arbeitnehmende damit gefährdet werden würden. Die Statistikwebsite Statista stuft bis zum Jahr 2025 über 7.5 Millionen Arbeitsplätze als gefährdet ein, wie akkurat diese Prognose ist wird sich jedoch noch zeigen. Die Beziehung von Menschen und Maschinen ist insbesondere komplex, wenn es um Algorithmen oder Künstlichen Intelligenzen geht. Es ist unbestritten, dass wir in vielen Bereichen unseres Lebens zunehmend von Technologie abhängig werden. Es ist daher entscheidend, dass man einen bewussten und informierten Umgang mit diesen Technologien fördert. Man muss sicherstellen, dass sie auf eine Weise eingesetzt werden, die unsere Werte respektiert und fördert, und dass wir die notwendigen Fähigkeiten und Kenntnisse entwickeln, um sie effektiv und verantwortungsvoll zu nutzen. Seit Jahren werden allerhand Algorithmen in jeglichen Einsatzgebieten eingesetzt, oft ohne dass dies dem Benutzer überhaupt bewusst wird. Sei es nur um einfach den schnellsten Weg zur nächsten Migros zu finden oder online nach Geschenken für ein Familienmitglied zu suchen: Beinahe alles wird von Algorithmen unterstützt oder erfasst. Blindes Vertrauen birgt aber auch Risiken: Mindestens eine Person kam ums Leben, weil ihr Navigationssystem anzeigte, eine Fährverbindung sei mit dem Auto überquerbar. Trotz solchen Fehlern werden diese Systeme weiterhin eingesetzt und weiterentwickelt, obwohl diese Technologien, die unser Leben vereinfachen sollen, sogar Todesfälle verursachen. Doch die Frage ist: Wie gross ist die Gefährdung für den Grossteil der Menschen? Unter dem Strich, nicht sehr gross, da die einzelnen Anwendungen keine starken Risiken bergen, Algorithmen sind im Alltag überall anzutreffen, sei es am Handy, an Ticketautomaten oder sogar bei einem einfachen Taschenrechner, und die Benützung dieser erfolgen meist ohne jegliche Nebenwirkungen. Letztendlich liegt die Macht nicht in den Maschinen selbst, sondern in der Art und Weise, wie man sie nutzt und kontrolliert. Es liegt an der Gesellschaft, das Gleichgewicht zu finden und zu bestimmen, wie diese Werkzeuge eingesetzt werden sollen. Mit diesem Gleichgewicht wird auch Nicolas Kiechler weiterhin unbesorgt seiner Neugierde nachgehen können.

###### Text: Alec und Aaron

## Quellenverzeichnis

* Paksy Plackis-Cheng, Dr. Tejo Chalasani, Sabrina Palme, et al. (10. Dezember, 2023). Ensuring Human Intelligence in AI Hiring Tools. Zugriff am 03. März 2024, von [https://findhr.eu/wp-content/uploads/2024/01/FINDHR-Expert-Report_by-Paksy-Plackis-Cheng-et-al.pdf](<* https://findhr.eu/wp-content/uploads/2024/01/FINDHR-Expert-Report_by-Paksy-Plackis-Cheng-et-al.pdf>)
* Algorithmwatch.ch. (Datum unbekannt). Diskriminierung 2.0: Wie Rassismus in Algorithmen weiterlebt. Zugriff am 03. März 2024, von 
  [https://algorithmwatch.ch/de/tag-gegen-rassismus-21-marz/](<* https://algorithmwatch.ch/de/tag-gegen-rassismus-21-marz/>)
* BCG. (27. November, 2017). Prognose zur Anzahl der potenziell gefährdeten Arbeitsplätze durch die Automatisierung in Deutschland nach Berufen bis zum Jahr 2025* (in Millionen) \[Graph]. In Statista. Zugriff am 05. Mai 2024, von <https://de.statista.com/statistik/daten/studie/814326/umfrage/prognose-gefaehrdete-arbeitsplaetze-durch-die-automatisierung-in-deutschland/>